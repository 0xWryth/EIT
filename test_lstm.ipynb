{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOT3u0GZKWc8"
   },
   "source": [
    "# Réseau de neurones: les bases en numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Irgrskx6KWc-"
   },
   "source": [
    "Le but de ce TP est de voir les bases des réseaux de neurones en numpy. Puis de voir comment en pratique on s'en sert avec la librairie Pytorch.\n",
    "\n",
    "Ce TP sera **à rendre** (voir Discord).\n",
    "Il y a n points dans ce TP, qui seront divisé pour obtenir une note sur 4.\n",
    "\n",
    "Ce TP est à faire avec votre **groupe**. Rendez-le avec votre **groupe**.\n",
    "\n",
    "Si vous avez des **questions**, n'hésitez pas à me les poser sur **Discord**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlmi-culKWdA"
   },
   "source": [
    "## Lecture des données, tokenization et BoW\n",
    "\n",
    "Dans cette section vous devez lire les données (seulement les consensus).\n",
    "\n",
    "Vous devez construire votre tokenizer (et de préférence le sauvegarder).\n",
    "\n",
    "Vous devez transformer votre jeu de données (liste de tweets et labels) en liste de vecteurs BoW + liste d'indice des labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9Ekg9fkKWdD"
   },
   "outputs": [],
   "source": [
    "# Les imports sont préparé ici\n",
    "# n'enlevez pas les % car il permettent le reload de modules ou l'affichage dans le notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 1** 1pt.\n",
    "\n",
    "Importez/réécrivez le code permettant de lire vos données et les transformer en BoW.\n",
    "\n",
    "A la fin de cette cellule, vous devrez avoir trois variables d'instanciées :\n",
    "- X : la liste des vecteurs BoW de vos tweets\n",
    "- Y_one_hot : la liste des indices des labels de vos tweets (Y_one_hot[i] doit contenir le label de X[i])\n",
    "- Y_one_hot : la liste des labels sous forme one_hot (c'est similaire à un BoW, vous prenez un vecteur de zeros et mettez un 1 à l'indice du label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G74xriNqIWKU"
   },
   "outputs": [],
   "source": [
    "def read_corpus(path, consensus=False):\n",
    "    f = open(path, 'r', encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    corpus = []\n",
    "    for l in lines:\n",
    "        sl = l.split()\n",
    "        if len(sl) == 0:\n",
    "            continue\n",
    "        if consensus:\n",
    "            m = re.match(r\"[(](.*),(.*),(consensus)[)]\", sl[0])\n",
    "            if m is not None:\n",
    "                corpus.append([sl[1:], sl[0]])\n",
    "        else:\n",
    "            corpus.append([sl[1:], sl[0]])\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "class WordTokenizer:\n",
    "    def __init__(self, bos='BOS', eos='EOS', unk='UNK', pad='PAD'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.word2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2word = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sent):\n",
    "        \"\"\"\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                self.word2id[w] = len(self.id2word.keys())\n",
    "                self.id2word[self.word2id[w]] = w\n",
    "\n",
    "    def str_to_ids(self, sentence):\n",
    "        sent = sentence.split()\n",
    "        ret = []\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                ret.append(self.word2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.word2id[w])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def words_to_ids(self, sent):\n",
    "        ret = []\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                ret.append(self.word2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.word2id[w])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_words(self, ids):\n",
    "        words = []\n",
    "        for i in ids:\n",
    "            words.append(self.id2word[i])\n",
    "        return words\n",
    "\n",
    "\n",
    "class CharTokenizer:\n",
    "    def __init__(self, bos='<B>', eos='<E>', unk='<U>', pad='<P>'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.char2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2char = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sentence):\n",
    "        \"\"\"\n",
    "        adds vocabulary (chars) found in sentence to the dictionaries\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for w in sentence:\n",
    "            if w not in self.char2id.keys():\n",
    "                self.char2id[w] = len(self.id2char.keys())\n",
    "                self.id2char[self.char2id[w]] = w\n",
    "\n",
    "    def chars_to_ids(self, sentence):\n",
    "        ret = []\n",
    "        for c in sentence:\n",
    "            if c not in self.char2id.keys():\n",
    "                ret.append(self.char2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.char2id[c])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_chars(self, ids):\n",
    "        chars = \"\"\n",
    "        for i in ids:\n",
    "            chars += self.id2char[i]\n",
    "        return chars\n",
    "\n",
    "\n",
    "class TrigramTokenizer:\n",
    "    def __init__(self, bos='<B>', eos='<E>', unk='<U>', pad='<P>'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.char2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2char = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sentence):\n",
    "        \"\"\"\n",
    "        adds vocabulary (chars) found in sentence to the dictionaries\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for i in range(len(sentence)-3):\n",
    "            if sentence[i:i+3] not in self.char2id.keys():\n",
    "                self.char2id[sentence[i:i+3]] = len(self.id2char.keys())\n",
    "                self.id2char[self.char2id[sentence[i:i+3]]] = sentence[i:i+3]\n",
    "\n",
    "    def chars_to_ids(self, sentence):\n",
    "        ret = []\n",
    "        for i in range(len(sentence)-3):\n",
    "            if sentence[i:i+3] not in self.char2id.keys():\n",
    "                ret.append(self.char2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.char2id[sentence[i:i+3]])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_chars(self, ids):\n",
    "        chars = \"\"\n",
    "        for i in ids:\n",
    "            chars += self.id2char[i]\n",
    "        return chars\n",
    "\n",
    "def list_to_bow(sent, dic):\n",
    "    \"sent list of ids, dic: dictionary {word, index}\"\n",
    "    vec = np.zeros(len(dic), dtype=int)\n",
    "    for i in sent:\n",
    "        vec[i] = 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "def list_to_bow_freq(sent, dic):\n",
    "    vec = np.zeros(len(dic))\n",
    "    for i in sent:\n",
    "        vec[i] += 1\n",
    "    for i in range(len(vec)):\n",
    "        vec[i] = vec[i] / len(sent)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def n_grams(sents, n):\n",
    "\n",
    "    new_sents = []\n",
    "    dic = {}\n",
    "\n",
    "    for s in sents:\n",
    "        ns = []\n",
    "        for i in range(len(s)-(n-1)):\n",
    "            t = \"\"\n",
    "            for j in range(n):\n",
    "                t += f\"{s[i+j]} \"\n",
    "            t = t[:-1]\n",
    "            ns.append(t)\n",
    "            if t not in dic:\n",
    "                dic[t] = len(dic.keys())\n",
    "\n",
    "        new_sents.append(ns)\n",
    "    return new_sents, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "11762\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "11762\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# mettez votre code ici\n",
    "\n",
    "corpus = read_corpus(\"./train_label_final.txt\", consensus=True)\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "labels = {'pos': 0, 'neg': 1, 'neu': 2, 'irr': 3}\n",
    "Y_one_hot = [] # Pour les labels il faut des vecteurs en one_hot, par exemple pour irr : [0,0,0,1]\n",
    "Y = []\n",
    "for i in range(len(corpus)):\n",
    "    lab = re.match(r\"[(].*,(.*),.*[)]\", corpus[i][1])\n",
    "    ap = np.zeros(len(labels.keys()))\n",
    "    ap[labels[lab[1].lower()]] = 1\n",
    "    Y.append(labels[lab[1].lower()])\n",
    "    Y_one_hot.append(ap)\n",
    "\n",
    "\n",
    "tweets = [c[0] for c in corpus]\n",
    "for t in tweets:\n",
    "    tokenizer.add_to_voc(t)\n",
    "\n",
    "    \n",
    "tweets_ids = [tokenizer.words_to_ids(t) for t in tweets]\n",
    "\n",
    "\n",
    "X = [list_to_bow(tw, tokenizer.word2id) for tw in tweets_ids]\n",
    "X_freq = [list_to_bow_freq(tw, tokenizer.word2id) for tw in tweets_ids]\n",
    "\n",
    "\n",
    "print(X[0]) # x sont les tweets transformés en vecteurs BoW\n",
    "print(len(X[0]))\n",
    "print(X_freq[0])\n",
    "print(len(X_freq[0]))\n",
    "print(Y_one_hot[0]) # y sont les labels transformés en indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzcMLu1KKWdx"
   },
   "source": [
    "## Algorithme d'apprentissage \n",
    "\n",
    "On a tout ce qu'il faut pour mettre en oeuvre l'apprentissage d'un modèle simple. Le modèle est simplement une couche neuronale de sortie, sans couche cachée. \n",
    "\n",
    "L'algorithme se déroule en 2 temps, tout d'abord la préparation: \n",
    "- initialisation du modèle\n",
    "- préparation des données et des variables permettant de stocker l'historique d'apprentissage\n",
    "- initialisation des paramètres de l'algorithme d'optimisation Adam\n",
    "- définir le nombre d'époque comme une variable\n",
    "\n",
    "Puis vient la boucle d'apprentissage qui pour chaque époque effectue pour chaque exemple d'apprentissage : \n",
    "- inférence du modèle sur l'exemple d'apprentissage \n",
    "- calcul de la contribution de l'exemple à la  fonction objectif, et également au taux d'erreur de classification\n",
    "- Calcul du gradient de sortie\n",
    "- Mise à jour du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie Pytorch permet la gestion des poids sous forme de couches dans le sous-module nn.\n",
    "La gestion du gradient est quasiment automatique.\n",
    "\n",
    "Le jeu de données sera les vecteurs BoW obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:1500]\n",
    "train_Y = Y_one_hot[:1500]\n",
    "train_Y_nhot = Y[:1500]\n",
    "\n",
    "valid_X = X[1500:]\n",
    "valid_Y = Y_one_hot[1500:]\n",
    "valid_Y_nhot = Y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example code of a simple RNN, GRU, LSTM on the MNIST dataset.\n",
    "\n",
    "Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n",
    "*    2020-05-09 Initial coding\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import torch as T\n",
    "import torchvision  # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "import torch.utils.data as data  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For a nice progress bar!\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if T.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 11** 3 pt\n",
    "\n",
    "Implémentez le même modèle que précédemment.\n",
    "\n",
    "Utilisez les couches Linear et LogSoftmax (les probabilités sont souvent des logs probabilités).\n",
    "Cherchez dans la documentation de torch.nn pour les couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network with LSTM (many-to-one)\n",
    "class RNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # todo : try to add bidirectionnal param :\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        print(h0)\n",
    "        print(h0.shape)\n",
    "        print(c0)\n",
    "        print(c0.shape)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 12** 2pt\n",
    "\n",
    "Complétez la boucle d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    return T.stack(transposed_data[0], 0), T.stack(transposed_data[1], 0)\n",
    "\n",
    "def train(train_X, train_Y, valid_X, valid_Y, epochs=100, batch_size=64, lr = 1e-3):\n",
    "    model = RNN_LSTM(len(train_X[0]), hidden_size, num_layers, 4).to(device)\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    opti = T.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss() # Pour calculer la crossentropy, il faut calculer la NLLL après un logsofmax\n",
    "    \n",
    "    \n",
    "    ## Transformation des données pour l'entraînement    \n",
    "    trn_X = T.tensor(train_X, dtype=T.float)\n",
    "    trn_Y = T.tensor(train_Y, dtype=T.long)\n",
    "    \n",
    "    vld_X = T.tensor(valid_X, dtype=T.float)\n",
    "    vld_Y = T.tensor(valid_Y, dtype=T.long)\n",
    "    \n",
    "    train_set = data.TensorDataset(trn_X, trn_Y)\n",
    "    valid_set = data.TensorDataset(vld_X, vld_Y)\n",
    "    \n",
    "    \n",
    "    ## Creation des loaders\n",
    "    train_sampler = data.BatchSampler(data.RandomSampler(range(len(train_X))), batch_size, False)\n",
    "    valid_sampler = data.BatchSampler(data.SequentialSampler(range(len(valid_X))), len(valid_X), False)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_set, batch_sampler=train_sampler, collate_fn=collate)\n",
    "    valid_loader = data.DataLoader(valid_set, batch_sampler=valid_sampler, collate_fn=collate)\n",
    "    \n",
    "    \n",
    "    losses = []\n",
    "    f1_valid = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        model.train() #passe votre modele en phase d'entrainement \n",
    "        \n",
    "        for batch_ndx, (trn_x, trn_y) in enumerate(train_loader):\n",
    "            opti.zero_grad()\n",
    "            \n",
    "            preds = model(trn_x.to(device))\n",
    "            loss = criterion(preds, trn_y.to(device))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            \n",
    "        opti.zero_grad()\n",
    "        model.eval()\n",
    "        \n",
    "        with T.no_grad(): # pour gagner du temps en ne générant pas de graphe pour la validation\n",
    "            for batch_ndx, (vld_x, vld_y) in enumerate(valid_loader):\n",
    "\n",
    "                preds_val = model(vld_x.to(device))\n",
    "                preds = T.argmax(preds_val, dim=1)\n",
    "                f1_valid.append(f1_score(vld_y.to('cpu').numpy(), preds.to('cpu').numpy(), average='micro',\n",
    "                                labels=[i for i in range(4)]))\n",
    "        print(f\"F1 {e}/{epochs}: {f1_valid[-1]}\")\n",
    "    \n",
    "    return model, losses, f1_valid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_LSTM(\n",
      "  (lstm): LSTM(11762, 256, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=7168, out_features=4, bias=True)\n",
      ")\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([64, 11762])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([64, 256])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([64, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-95a1b1046089>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y_nhot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_Y_nhot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-389fd6267005>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_X, train_Y, valid_X, valid_Y, epochs, batch_size, lr)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mopti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-f3eee8bc7844>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Forward propagate LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         out, _ = self.lstm(\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                            ):\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    201\u001b[0m             raise RuntimeError(\n\u001b[0;32m    202\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m--> 203\u001b[1;33m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "model, losses, f1_valid = train(train_X, train_Y_nhot, valid_X, valid_Y_nhot, epochs=200, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([x/(len(losses)/100) for x in range(len(losses))],losses, label=\"loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f1_valid, label='f1')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "bestIndex = np.argmax(f1_valid)\n",
    "bestNC, bestScore = np.arange(0, 200, 1)[bestIndex], f1_valid[bestIndex]\n",
    "plt.plot(bestNC, f1_valid[bestIndex], marker='X', color='green')\n",
    "plt.title(\"Best score: ~{0:.1%} (obtained on {1})\".format(bestScore, device))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Score du modèle fourni initialement : ~68%_\n",
    "\n",
    "C'est super! Vous avez fini."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
