{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet d'extraction d'informations à partir de textes\n",
    "## NLP et Réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas enlever les % car il permettent le reload de modules ou l'affichage dans le notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchtext\n",
    "#from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import spacy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "device = 'cuda' if T.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commandes utiles en cas de librairies manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchtext\n",
    "# !pip3 install -U spacy                       # spaCy lib\n",
    "# !pip3 install torch torchvision torchaudio   # PyTorch (see <pytorch.org/get-started/locally> for GPU support)\n",
    "# !python3 -m spacy download en_core_web_trf    # download spaCy trained pipeline\n",
    "\n",
    "# et pour certains :\n",
    "# pip install transformers -U\n",
    "\n",
    "# et pour tester d'autres modèles :\n",
    "# !python3 -m spacy download xx_ent_wiki_sm    # download spaCy trained pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'train_label_final.txt'\n",
    "lines = open(filename,\"r\", encoding='UTF-8').readlines()\n",
    "nb_lines = len(lines)\n",
    "nb_lines_half = math.ceil(nb_lines*0.7)\n",
    "# Avec le code actuel, comme on fait nb_lines/2 = nb_lines*0.5, la répartition entre les 2 fichiers est de 50%/50%\n",
    "# Ainsi, si on veut une répartition de 70%/30% pour jeu d'entrainement/validation, il suffit de faire nb_lines*0.7\n",
    "# --> nb_lines*x , avec x>=0.5 sinon on a 3 fichiers\n",
    "print(nb_lines_half)\n",
    "\n",
    "fout = open(\"output0.txt\",\"wt\", encoding='UTF-8')\n",
    "for i,line in enumerate(lines):\n",
    "    \n",
    "    if((i+1)%nb_lines_half) == 0:\n",
    "        line = str(line).replace('\\n', '')\n",
    "        \n",
    "    if (i%nb_lines_half) == 0:\n",
    "        if fout: fout.close()\n",
    "        fout = open('output%d.txt' % (i/nb_lines_half), 'w', encoding='UTF-8')\n",
    "        \n",
    "    fout.write(line)\n",
    "    \n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./output0.txt\"\n",
    "path2 = \"./output1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_txt_to_csv(path, out):\n",
    "    f = open(path, \"r\", encoding=\"UTF-8\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    decisions = [\"pos\", \"neg\", \"neu\", \"irr\"]\n",
    "\n",
    "    # Future CSV content !\n",
    "    content = \"text,opinion\"\n",
    "\n",
    "    for l in lines:\n",
    "        # Removing empty lines\n",
    "        sl = l.split()\n",
    "        if len(sl) == 0:\n",
    "            continue\n",
    "\n",
    "        # Removing no consensus line\n",
    "        m = re.match(r\"[(](.*),(.*),(consensus)[)]\", sl[0])\n",
    "        if m is None:\n",
    "            continue\n",
    "\n",
    "        # Parsing opinion\n",
    "        try:\n",
    "            opinion = m.string.split(\",\")[1]\n",
    "            if opinion in decisions:\n",
    "                # Opinion string is converted to an integer value\n",
    "                index = decisions.index(opinion)\n",
    "\n",
    "                # Removing opinion\n",
    "                text = re.sub(r\"[(](.*),(.*),(consensus)[)]\", \"\", l)\n",
    "\n",
    "                # Removing comma since comma is CSV separator\n",
    "                text = text.replace(\",\", \" \")\n",
    "\n",
    "                # Remvoing extra \\n\n",
    "                text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "                # Removing extra space\n",
    "                text = ' '.join(text.split())\n",
    "\n",
    "                content = content + \"\\n\" + text + \",\" + str(index) \n",
    "            else:\n",
    "                # Found opinion is... Wrong !\n",
    "                continue\n",
    "        except:\n",
    "            # Opinion is not found on the line\n",
    "            continue\n",
    "\n",
    "    # Writing CSV content to out file\n",
    "    csv = open(out, \"w\", encoding=\"UTF-8\")\n",
    "    csv.write(content)\n",
    "    csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_txt_to_csv(path, \"dataset.csv\")\n",
    "convert_txt_to_csv(path2, \"dataset2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture et traitement des données & Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthode de Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a way to merge EN & FR language pipelines\n",
    "spacy_en = spacy.load('en_core_web_trf')\n",
    "#spacy_en = spacy.load('xx_ent_wiki_sm') # multi language\n",
    "# --> moins bien dans notre cas car moins spécifiquement entrainé sur un langage en particulier. De plus, la taille du fichier telecharge ici est beaucoup plus petit.\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prétraitement sur le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_constructor = Field(sequential = True, lower = True, include_lengths = False,\n",
    "            pad_token = \"<pad>\", unk_token = \"<unk>\",\n",
    "            batch_first = True, tokenize = tokenizer)\n",
    "\n",
    "Y_constructor = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = TabularDataset.splits(\n",
    "    path=\"./\", format=\"csv\", \n",
    "    train='dataset.csv', test='dataset2.csv',\n",
    "    skip_header = True,\n",
    "    fields=[('x', X_constructor), ('y', Y_constructor)])\n",
    "\n",
    "#train_dataset[0].x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gestion des batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 176 # pour la validation on fait varier entre 16 et 256 par pas de 16\n",
    "\n",
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    (train_dataset, test_dataset), batch_size=batch_size, #batch_sizes=(16, 256) --> min=16 and max=256\n",
    "    sort_key = lambda m: len(m.x), device=device,\n",
    "    sort_within_batch = True, shuffle = True, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gestion du vocabulaire et des word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_constructor.build_vocab(train_dataset, min_freq=2, vectors = 'glove.6B.50d')\n",
    "#X_constructor.build_vocab(train_dataset, min_freq=2, vectors = 'glove.6B.100d')\n",
    "batch = next(iter(train_iter))\n",
    "\n",
    "batch.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_dim=50):\n",
    "    #def __init__(self, embedding_dim=100):\n",
    "        super(Model, self).__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(X_constructor.vocab.vectors, freeze = False)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = embedding_dim, num_layers = 3, batch_first = True, bidirectional = False)\n",
    "        self.fc = nn.Linear(embedding_dim, 4) # {pos,neg,neu,irr}\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # couche d'activation\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs) # pour faire le lien entre indice et vecteur du mot associé\n",
    "        outputs, (h_n,c_n) = self.lstm(embeds)\n",
    "        y = h_n[0]\n",
    "        y = self.fc(y)\n",
    "        #return y\n",
    "        preds = self.softmax(y) # couche d'activation\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(embedding_dim = 50).to(device)\n",
    "#model = Model(embedding_dim = 100).to(device)\n",
    "# embedding_dim = 50 car la taille de chaque vecteur de représentation des mots par l'embedding utilisé à partir de\n",
    "# la base du fichier \"glove.6B.50d\", est de taille 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucles d'entraînement et de mesure des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    return T.stack(transposed_data[0], 0), T.stack(transposed_data[1], 0)\n",
    "\n",
    "def train(epochs=100, batch_size=batch_size, lr = 1e-3):\n",
    "    #model = Model(len(train_X[0]), 4).to(device)\n",
    "    \n",
    "    optimizer = T.optim.Adam(model.parameters(), lr=lr)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.01) # triman\n",
    "    criterion = nn.NLLLoss() # Pour calculer la crossentropy, il faut calculer la NLLL après un logsofmax\n",
    "    #criterion = nn.CrossEntropyLoss() # triman\n",
    "    \n",
    "    ## Transformation des données pour l'entraînement\n",
    "    #trn_X = [T.tensor(x, dtype=T.long) for x in train_X]\n",
    "    #trn_Y = [T.tensor(y, dtype=T.long) for y in train_Y]\n",
    "    \n",
    "    #vld_X = [T.tensor(x, dtype=T.long) for x in valid_X]\n",
    "    #vld_Y = [T.tensor(y, dtype=T.long) for y in valid_Y]\n",
    "    \n",
    "    \"\"\"\n",
    "    #trn_X = T.tensor(train_X, dtype=T.float)\n",
    "    #trn_Y = T.tensor(train_Y, dtype=T.long)\n",
    "    \n",
    "    #vld_X = T.tensor(valid_X, dtype=T.float)\n",
    "    #vld_Y = T.tensor(valid_Y, dtype=T.long)\n",
    "    \n",
    "    train_set = data.TensorDataset(trn_X, trn_Y)\n",
    "    valid_set = data.TensorDataset(vld_X, vld_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Creation des loaders\n",
    "    train_sampler = data.BatchSampler(data.RandomSampler(range(len(train_X))), batch_size, False)\n",
    "    valid_sampler = data.BatchSampler(data.SequentialSampler(range(len(valid_X))), len(valid_X), False)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_set, batch_sampler=train_sampler, collate_fn=collate)\n",
    "    valid_loader = data.DataLoader(valid_set, batch_sampler=valid_sampler, collate_fn=collate)\n",
    "    \"\"\"\n",
    "    \n",
    "    losses = []\n",
    "    f1_valid = []\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        model.train() #passe votre modele en phase d'entrainement\n",
    "        \n",
    "        for batch in train_iter:\n",
    "        #for i in range(0, train_iter.batch_size):\n",
    "            try:\n",
    "                #optimizer.zero_grad()\n",
    "                \n",
    "                #batch = next(iter(train_iter))\n",
    "                data = batch.x.to(device)\n",
    "                labels = batch.y.to(device)\n",
    "\n",
    "                preds = model(data)\n",
    "                loss = criterion(preds, labels)\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            except:\n",
    "                print(\"not done\")\n",
    "                \n",
    "        #optimizer.zero_grad()\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_iter:\n",
    "            #for j in range(0, test_iter.batch_size):\n",
    "                try:\n",
    "                    #batch = next(iter(test_iter))\n",
    "                    data = batch.x.to(device)\n",
    "                    labels = batch.y.to(device)\n",
    "\n",
    "                    preds_val = model(data)\n",
    "                    preds = T.argmax(preds_val, dim=1)\n",
    "                    #_, preds = torch.max(preds_val.data, 1)\n",
    "                    \n",
    "                    f1_valid.append(f1_score(labels.to('cpu').numpy(), preds.to('cpu').numpy(), average='micro',\n",
    "                                labels=[i for i in range(4)]))\n",
    "                except:\n",
    "                    print(\"error\")\n",
    "\n",
    "        print(f\"F1 {e}/{epochs}: {f1_valid[-1]}\")\n",
    "        \n",
    "    \n",
    "    return model, losses, f1_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, losses, f1_valid = train(epochs=200, lr=1e-4) # batch_size=(batch_size = 128) ici\n",
    "# De base : epochs=100, batch_size=64, lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résultats et scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x/(len(losses)/100) for x in range(len(losses))],losses, label=\"loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(f1_valid, label='f1')\n",
    "#plt.legend(loc='best')\n",
    "\n",
    "#bestIndex = np.argmax(f1_valid)\n",
    "#bestNC, bestScore = np.arange(0, 200, 1)[bestIndex], f1_valid[bestIndex]\n",
    "#plt.plot(bestNC, f1_valid[bestIndex], marker='X', color='green')\n",
    "#plt.title(\"Best score: ~{0:.1%} (obtained on {1})\".format(bestScore, device))\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "plt.plot(f1_valid, label='f1')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iter:\n",
    "    #for j in range(0, test_iter.batch_size):\n",
    "        try:\n",
    "            #batch = next(iter(test_iter))\n",
    "            data = batch.x.to(device)\n",
    "            labels = batch.y.to(device)\n",
    "\n",
    "            preds_val = model(data)\n",
    "            #preds = T.argmax(preds_val, dim=1)\n",
    "            _, preds = torch.max(preds_val.data, 1)\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        except:\n",
    "            print(\"error\")\n",
    "\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_preds = np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(all_labels,all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "matrice = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrice, display_labels=['pos', 'neg', 'neu', 'irr'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
