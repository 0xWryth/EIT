{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOT3u0GZKWc8"
   },
   "source": [
    "# Réseau de neurones: les bases en numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Irgrskx6KWc-"
   },
   "source": [
    "Le but de ce TP est de voir les bases des réseaux de neurones en numpy. Puis de voir comment en pratique on s'en sert avec la librairie Pytorch.\n",
    "\n",
    "Ce TP sera **à rendre** (voir Discord).\n",
    "Il y a n points dans ce TP, qui seront divisé pour obtenir une note sur 4.\n",
    "\n",
    "Ce TP est à faire avec votre **groupe**. Rendez-le avec votre **groupe**.\n",
    "\n",
    "Si vous avez des **questions**, n'hésitez pas à me les poser sur **Discord**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlmi-culKWdA"
   },
   "source": [
    "## Lecture des données, tokenization et BoW\n",
    "\n",
    "Dans cette section vous devez lire les données (seulement les consensus).\n",
    "\n",
    "Vous devez construire votre tokenizer (et de préférence le sauvegarder).\n",
    "\n",
    "Vous devez transformer votre jeu de données (liste de tweets et labels) en liste de vecteurs BoW + liste d'indice des labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9Ekg9fkKWdD"
   },
   "outputs": [],
   "source": [
    "# Les imports sont préparé ici\n",
    "# n'enlevez pas les % car il permettent le reload de modules ou l'affichage dans le notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field, TabularDataset, Dataset, BucketIterator\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-b64e6fa215f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#train_dataset, test_dataset = Dataset.splits(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "TEXT = Field(sequential = True, lower=True, include_lengths = False,\n",
    "                  pad_token = \"<pad>\", unk_token = \"<unk>\",\n",
    "                  batch_first = True, tokenize = tokenizer)\n",
    "\n",
    "LABELS = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "\n",
    "trainset = Dataset([\"aled\", \"aled2\"], [('text', TEXT), ('labels', LABELS)])\n",
    "validset = Dataset([\"aled3\", \"aled4\"], [('text', TEXT), ('labels', LABELS)])\n",
    "\n",
    "trainset, validset\n",
    "\n",
    "type(trainset[0])\n",
    "\n",
    "#trainset.labels[1]\n",
    "\n",
    "#train_dataset, test_dataset = Dataset.splits(\n",
    "#    path='./',\n",
    "#    fields=[('text', TEXT), ('labels', LABELS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-4a211a206289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'glove.6B.50d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Size vocab :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0msources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=2, vectors = 'glove.6B.50d')\n",
    "print(\"Size vocab :\", len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-4a0e88a0b024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     shuffle = True, repeat=False)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, dataset, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    (trainset,  validset), batch_sizes=(16, 256),\n",
    "    sort_key = lambda x: len(x.text), device='cpu', \n",
    "    sort_within_batch = True, shuffle = True, repeat=False)\n",
    "\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 1** 1pt.\n",
    "\n",
    "Importez/réécrivez le code permettant de lire vos données et les transformer en BoW.\n",
    "\n",
    "A la fin de cette cellule, vous devrez avoir trois variables d'instanciées :\n",
    "- X : la liste des vecteurs BoW de vos tweets\n",
    "- Y_one_hot : la liste des indices des labels de vos tweets (Y_one_hot[i] doit contenir le label de X[i])\n",
    "- Y_one_hot : la liste des labels sous forme one_hot (c'est similaire à un BoW, vous prenez un vecteur de zeros et mettez un 1 à l'indice du label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G74xriNqIWKU"
   },
   "outputs": [],
   "source": [
    "def read_corpus(path, consensus=False):\n",
    "    f = open(path, 'r', encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    corpus = []\n",
    "    for l in lines:\n",
    "        sl = l.split()\n",
    "        if len(sl) == 0:\n",
    "            continue\n",
    "        if consensus:\n",
    "            m = re.match(r\"[(](.*),(.*),(consensus)[)]\", sl[0])\n",
    "            if m is not None:\n",
    "                corpus.append([sl[1:], sl[0]])\n",
    "        else:\n",
    "            corpus.append([sl[1:], sl[0]])\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "class WordTokenizer:\n",
    "    def __init__(self, bos='BOS', eos='EOS', unk='UNK', pad='PAD'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.word2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2word = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sent):\n",
    "        \"\"\"\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                self.word2id[w] = len(self.id2word.keys())\n",
    "                self.id2word[self.word2id[w]] = w\n",
    "\n",
    "    def str_to_ids(self, sentence):\n",
    "        sent = sentence.split()\n",
    "        ret = []\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                ret.append(self.word2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.word2id[w])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def words_to_ids(self, sent):\n",
    "        ret = []\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                ret.append(self.word2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.word2id[w])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_words(self, ids):\n",
    "        words = []\n",
    "        for i in ids:\n",
    "            words.append(self.id2word[i])\n",
    "        return words\n",
    "\n",
    "\n",
    "class CharTokenizer:\n",
    "    def __init__(self, bos='<B>', eos='<E>', unk='<U>', pad='<P>'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.char2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2char = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sentence):\n",
    "        \"\"\"\n",
    "        adds vocabulary (chars) found in sentence to the dictionaries\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for w in sentence:\n",
    "            if w not in self.char2id.keys():\n",
    "                self.char2id[w] = len(self.id2char.keys())\n",
    "                self.id2char[self.char2id[w]] = w\n",
    "\n",
    "    def chars_to_ids(self, sentence):\n",
    "        ret = []\n",
    "        for c in sentence:\n",
    "            if c not in self.char2id.keys():\n",
    "                ret.append(self.char2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.char2id[c])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_chars(self, ids):\n",
    "        chars = \"\"\n",
    "        for i in ids:\n",
    "            chars += self.id2char[i]\n",
    "        return chars\n",
    "\n",
    "\n",
    "class TrigramTokenizer:\n",
    "    def __init__(self, bos='<B>', eos='<E>', unk='<U>', pad='<P>'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.char2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2char = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sentence):\n",
    "        \"\"\"\n",
    "        adds vocabulary (chars) found in sentence to the dictionaries\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for i in range(len(sentence)-3):\n",
    "            if sentence[i:i+3] not in self.char2id.keys():\n",
    "                self.char2id[sentence[i:i+3]] = len(self.id2char.keys())\n",
    "                self.id2char[self.char2id[sentence[i:i+3]]] = sentence[i:i+3]\n",
    "\n",
    "    def chars_to_ids(self, sentence):\n",
    "        ret = []\n",
    "        for i in range(len(sentence)-3):\n",
    "            if sentence[i:i+3] not in self.char2id.keys():\n",
    "                ret.append(self.char2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.char2id[sentence[i:i+3]])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_chars(self, ids):\n",
    "        chars = \"\"\n",
    "        for i in ids:\n",
    "            chars += self.id2char[i]\n",
    "        return chars\n",
    "\n",
    "def list_to_bow(sent, dic):\n",
    "    \"sent list of ids, dic: dictionary {word, index}\"\n",
    "    vec = np.zeros(len(dic), dtype=int)\n",
    "    for i in sent:\n",
    "        vec[i] = 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "def list_to_bow_freq(sent, dic):\n",
    "    vec = np.zeros(len(dic))\n",
    "    for i in sent:\n",
    "        vec[i] += 1\n",
    "    for i in range(len(vec)):\n",
    "        vec[i] = vec[i] / len(sent)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def n_grams(sents, n):\n",
    "\n",
    "    new_sents = []\n",
    "    dic = {}\n",
    "\n",
    "    for s in sents:\n",
    "        ns = []\n",
    "        for i in range(len(s)-(n-1)):\n",
    "            t = \"\"\n",
    "            for j in range(n):\n",
    "                t += f\"{s[i+j]} \"\n",
    "            t = t[:-1]\n",
    "            ns.append(t)\n",
    "            if t not in dic:\n",
    "                dic[t] = len(dic.keys())\n",
    "\n",
    "        new_sents.append(ns)\n",
    "    return new_sents, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "11762\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "11762\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# mettez votre code ici\n",
    "\n",
    "corpus = read_corpus(\"./train_label_final.txt\", consensus=True)\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "labels = {'pos': 0, 'neg': 1, 'neu': 2, 'irr': 3}\n",
    "Y_one_hot = [] # Pour les labels il faut des vecteurs en one_hot, par exemple pour irr : [0,0,0,1]\n",
    "Y = []\n",
    "for i in range(len(corpus)):\n",
    "    lab = re.match(r\"[(].*,(.*),.*[)]\", corpus[i][1])\n",
    "    ap = np.zeros(len(labels.keys()))\n",
    "    ap[labels[lab[1].lower()]] = 1\n",
    "    Y.append(labels[lab[1].lower()])\n",
    "    Y_one_hot.append(ap)\n",
    "\n",
    "\n",
    "tweets = [c[0] for c in corpus]\n",
    "for t in tweets:\n",
    "    tokenizer.add_to_voc(t)\n",
    "\n",
    "    \n",
    "tweets_ids = [tokenizer.words_to_ids(t) for t in tweets]\n",
    "\n",
    "\n",
    "X = [list_to_bow(tw, tokenizer.word2id) for tw in tweets_ids]\n",
    "X_freq = [list_to_bow_freq(tw, tokenizer.word2id) for tw in tweets_ids]\n",
    "\n",
    "\n",
    "print(X[0]) # x sont les tweets transformés en vecteurs BoW\n",
    "print(len(X[0]))\n",
    "print(X_freq[0])\n",
    "print(len(X_freq[0]))\n",
    "print(Y_one_hot[0]) # y sont les labels transformés en indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvZIFXNNKWdV"
   },
   "source": [
    "## Création du modèle\n",
    "\n",
    "Nous allons d'abord créer une couche linéaire.\n",
    "Celle ci comprendra le terme de biais.\n",
    "\n",
    "Rappel de la formule de la couche linéaire: \n",
    "$$\n",
    "\\mathbf{a} = \\mathbf{W}\\mathbf{x}+ \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Notons *n_in* et *n_out* respectivement les dimensions de $\\mathbf{x}$ et $\\mathbf{y}$. \n",
    "\n",
    "**Tache 2** 1pt.\n",
    "- Coder la fonction d'initialisation suivante, l'initialisation est aléatoire Gaussien centrée en 0 avec un écart type 1 / sqrt(n_in). La fonction retourne W et b. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzcMLu1KKWdx"
   },
   "source": [
    "## Algorithme d'apprentissage \n",
    "\n",
    "On a tout ce qu'il faut pour mettre en oeuvre l'apprentissage d'un modèle simple. Le modèle est simplement une couche neuronale de sortie, sans couche cachée. \n",
    "\n",
    "L'algorithme se déroule en 2 temps, tout d'abord la préparation: \n",
    "- initialisation du modèle\n",
    "- préparation des données et des variables permettant de stocker l'historique d'apprentissage\n",
    "- initialisation des paramètres de l'algorithme d'optimisation Adam\n",
    "- définir le nombre d'époque comme une variable\n",
    "\n",
    "Puis vient la boucle d'apprentissage qui pour chaque époque effectue pour chaque exemple d'apprentissage : \n",
    "- inférence du modèle sur l'exemple d'apprentissage \n",
    "- calcul de la contribution de l'exemple à la  fonction objectif, et également au taux d'erreur de classification\n",
    "- Calcul du gradient de sortie\n",
    "- Mise à jour du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 :  PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de cette section est de répliquer ce que vous avez fait à la main grâce à une librairie spécialisée.\n",
    "\n",
    "Cette librairie est Pytorch.\n",
    "\n",
    "Dans cette librairie vous retrouverez la gestion des poids sous forme de couches dans le sous-module nn.\n",
    "La gestion du gradient est quasiment automatique.\n",
    "\n",
    "Le jeu de données sera toujours les vecteurs BoW obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:1500]\n",
    "train_Y = Y_one_hot[:1500]\n",
    "train_Y_nhot = Y[:1500]\n",
    "\n",
    "valid_X = X[1500:]\n",
    "valid_Y = Y_one_hot[1500:]\n",
    "valid_Y_nhot = Y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "device = 'cuda' if T.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 11** 3 pt\n",
    "\n",
    "Implémentez le même modèle que précédemment.\n",
    "\n",
    "Utilisez les couches Linear et LogSoftmax (les probabilités sont souvent des logs probabilités).\n",
    "Cherchez dans la documentation de torch.nn pour les couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): # pour faire un modèle dans pytorch il faut instancier la classe nn.Module\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.embeding = nn.Embedding(in_dim, out_dim)\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim) # Ici se trouve la couche Wx + b\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # Pour pytorch, la plupars des fonction fonctionne avec des logarithmes\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Quelque soit le modèle, il vous faut une fonction forward\n",
    "        # Pour calculer la sortie d'une couche : y = couche(x) avec x un tensor\n",
    "        #embeds = self.embeding(inputs.to(T.int64))\n",
    "        # print(inputs.shape)\n",
    "        y = T.tanh(self.linear1(inputs))\n",
    "        preds = self.softmax(y)\n",
    "        return preds    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 12** 2pt\n",
    "\n",
    "Complétez la boucle d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    return T.stack(transposed_data[0], 0), T.stack(transposed_data[1], 0)\n",
    "\n",
    "def train(train_X, train_Y, valid_X, valid_Y, epochs=100, batch_size=64, lr = 1e-3):\n",
    "    model = Model(len(train_X[0]), 4).to(device)\n",
    "    \n",
    "    opti = T.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss() # Pour calculer la crossentropy, il faut calculer la NLLL après un logsofmax\n",
    "    \n",
    "    \n",
    "    ## Transformation des données pour l'entraînement\n",
    "    #trn_X = [T.tensor(x, dtype=T.long) for x in train_X]\n",
    "    #trn_Y = [T.tensor(y, dtype=T.long) for y in train_Y]\n",
    "    \n",
    "    #vld_X = [T.tensor(x, dtype=T.long) for x in valid_X]\n",
    "    #vld_Y = [T.tensor(y, dtype=T.long) for y in valid_Y]\n",
    "    \n",
    "    trn_X = T.tensor(train_X, dtype=T.float)\n",
    "    trn_Y = T.tensor(train_Y, dtype=T.long)\n",
    "    \n",
    "    vld_X = T.tensor(valid_X, dtype=T.float)\n",
    "    vld_Y = T.tensor(valid_Y, dtype=T.long)\n",
    "    \n",
    "    train_set = data.TensorDataset(trn_X, trn_Y)\n",
    "    valid_set = data.TensorDataset(vld_X, vld_Y)\n",
    "    \n",
    "    \n",
    "    ## Creation des loaders\n",
    "    train_sampler = data.BatchSampler(data.RandomSampler(range(len(train_X))), batch_size, False)\n",
    "    valid_sampler = data.BatchSampler(data.SequentialSampler(range(len(valid_X))), len(valid_X), False)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_set, batch_sampler=train_sampler, collate_fn=collate)\n",
    "    valid_loader = data.DataLoader(valid_set, batch_sampler=valid_sampler, collate_fn=collate)\n",
    "    \n",
    "    \n",
    "    losses = []\n",
    "    f1_valid = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        model.train() #passe votre modele en phase d'entrainement \n",
    "        \n",
    "        for batch_ndx, (trn_x, trn_y) in enumerate(train_loader):\n",
    "            opti.zero_grad()\n",
    "            \n",
    "            preds = model(trn_x.to(device))\n",
    "            loss = criterion(preds, trn_y.to(device))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            \n",
    "        opti.zero_grad()\n",
    "        model.eval()\n",
    "        \n",
    "        with T.no_grad(): # pour gagner du temps en ne générant pas de graphe pour la validation\n",
    "            for batch_ndx, (vld_x, vld_y) in enumerate(valid_loader):\n",
    "\n",
    "                preds_val = model(vld_x.to(device))\n",
    "                preds = T.argmax(preds_val, dim=1)\n",
    "                f1_valid.append(f1_score(vld_y.to('cpu').numpy(), preds.to('cpu').numpy(), average='micro',\n",
    "                                labels=[i for i in range(4)]))\n",
    "        print(f\"F1 {e}/{epochs}: {f1_valid[-1]}\")\n",
    "    \n",
    "    return model, losses, f1_valid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0/200: 0.3643926788685524\n",
      "F1 1/200: 0.47920133111480867\n",
      "F1 2/200: 0.5574043261231281\n",
      "F1 3/200: 0.6006655574043261\n",
      "F1 4/200: 0.6123128119800333\n",
      "F1 5/200: 0.6089850249584027\n",
      "F1 6/200: 0.6206322795341098\n",
      "F1 7/200: 0.6256239600665557\n",
      "F1 8/200: 0.627287853577371\n",
      "F1 9/200: 0.6306156405990017\n",
      "F1 10/200: 0.627287853577371\n",
      "F1 11/200: 0.6289517470881864\n",
      "F1 12/200: 0.632279534109817\n",
      "F1 13/200: 0.632279534109817\n",
      "F1 14/200: 0.6289517470881864\n",
      "F1 15/200: 0.6289517470881864\n",
      "F1 16/200: 0.6289517470881864\n",
      "F1 17/200: 0.627287853577371\n",
      "F1 18/200: 0.6256239600665557\n",
      "F1 19/200: 0.627287853577371\n",
      "F1 20/200: 0.627287853577371\n",
      "F1 21/200: 0.6289517470881864\n",
      "F1 22/200: 0.6306156405990017\n",
      "F1 23/200: 0.6289517470881864\n",
      "F1 24/200: 0.6289517470881864\n",
      "F1 25/200: 0.6289517470881864\n",
      "F1 26/200: 0.6306156405990017\n",
      "F1 27/200: 0.6306156405990017\n",
      "F1 28/200: 0.6306156405990017\n",
      "F1 29/200: 0.6289517470881864\n",
      "F1 30/200: 0.6289517470881864\n",
      "F1 31/200: 0.6306156405990017\n",
      "F1 32/200: 0.6306156405990017\n",
      "F1 33/200: 0.6306156405990017\n",
      "F1 34/200: 0.632279534109817\n",
      "F1 35/200: 0.632279534109817\n",
      "F1 36/200: 0.632279534109817\n",
      "F1 37/200: 0.6339434276206323\n",
      "F1 38/200: 0.6339434276206323\n",
      "F1 39/200: 0.632279534109817\n",
      "F1 40/200: 0.6339434276206323\n",
      "F1 41/200: 0.6339434276206323\n",
      "F1 42/200: 0.6339434276206323\n",
      "F1 43/200: 0.6339434276206323\n",
      "F1 44/200: 0.6339434276206323\n",
      "F1 45/200: 0.632279534109817\n",
      "F1 46/200: 0.632279534109817\n",
      "F1 47/200: 0.632279534109817\n",
      "F1 48/200: 0.632279534109817\n",
      "F1 49/200: 0.6339434276206323\n",
      "F1 50/200: 0.6339434276206323\n",
      "F1 51/200: 0.6339434276206323\n",
      "F1 52/200: 0.632279534109817\n",
      "F1 53/200: 0.6339434276206323\n",
      "F1 54/200: 0.6356073211314476\n",
      "F1 55/200: 0.6372712146422629\n",
      "F1 56/200: 0.6405990016638935\n",
      "F1 57/200: 0.6405990016638935\n",
      "F1 58/200: 0.6422628951747088\n",
      "F1 59/200: 0.6439267886855241\n",
      "F1 60/200: 0.6439267886855241\n",
      "F1 61/200: 0.6455906821963394\n",
      "F1 62/200: 0.6455906821963394\n",
      "F1 63/200: 0.6455906821963394\n",
      "F1 64/200: 0.6439267886855241\n",
      "F1 65/200: 0.6472545757071547\n",
      "F1 66/200: 0.6472545757071547\n",
      "F1 67/200: 0.6472545757071547\n",
      "F1 68/200: 0.6472545757071547\n",
      "F1 69/200: 0.64891846921797\n",
      "F1 70/200: 0.64891846921797\n",
      "F1 71/200: 0.6505823627287853\n",
      "F1 72/200: 0.6505823627287853\n",
      "F1 73/200: 0.6505823627287853\n",
      "F1 74/200: 0.6505823627287853\n",
      "F1 75/200: 0.6505823627287853\n",
      "F1 76/200: 0.6505823627287853\n",
      "F1 77/200: 0.6505823627287853\n",
      "F1 78/200: 0.6505823627287853\n",
      "F1 79/200: 0.6505823627287853\n",
      "F1 80/200: 0.6505823627287853\n",
      "F1 81/200: 0.6505823627287853\n",
      "F1 82/200: 0.6522462562396006\n",
      "F1 83/200: 0.653910149750416\n",
      "F1 84/200: 0.6555740432612313\n",
      "F1 85/200: 0.6555740432612313\n",
      "F1 86/200: 0.6572379367720466\n",
      "F1 87/200: 0.6572379367720466\n",
      "F1 88/200: 0.6572379367720466\n",
      "F1 89/200: 0.6572379367720466\n",
      "F1 90/200: 0.6589018302828619\n",
      "F1 91/200: 0.6589018302828619\n",
      "F1 92/200: 0.6589018302828619\n",
      "F1 93/200: 0.6589018302828619\n",
      "F1 94/200: 0.6605657237936772\n",
      "F1 95/200: 0.6589018302828619\n",
      "F1 96/200: 0.6589018302828619\n",
      "F1 97/200: 0.6605657237936772\n",
      "F1 98/200: 0.6605657237936772\n",
      "F1 99/200: 0.6605657237936772\n",
      "F1 100/200: 0.6622296173044925\n",
      "F1 101/200: 0.6638935108153078\n",
      "F1 102/200: 0.6655574043261231\n",
      "F1 103/200: 0.6655574043261231\n",
      "F1 104/200: 0.6655574043261231\n",
      "F1 105/200: 0.6655574043261231\n",
      "F1 106/200: 0.6655574043261231\n",
      "F1 107/200: 0.6655574043261231\n",
      "F1 108/200: 0.6655574043261231\n",
      "F1 109/200: 0.6672212978369384\n",
      "F1 110/200: 0.6672212978369384\n",
      "F1 111/200: 0.6688851913477537\n",
      "F1 112/200: 0.670549084858569\n",
      "F1 113/200: 0.670549084858569\n",
      "F1 114/200: 0.670549084858569\n",
      "F1 115/200: 0.6722129783693843\n",
      "F1 116/200: 0.6738768718801996\n",
      "F1 117/200: 0.6738768718801996\n",
      "F1 118/200: 0.6738768718801996\n",
      "F1 119/200: 0.6755407653910149\n",
      "F1 120/200: 0.6755407653910149\n",
      "F1 121/200: 0.6755407653910149\n",
      "F1 122/200: 0.6755407653910149\n",
      "F1 123/200: 0.6755407653910149\n",
      "F1 124/200: 0.6755407653910149\n",
      "F1 125/200: 0.6772046589018302\n",
      "F1 126/200: 0.6755407653910149\n",
      "F1 127/200: 0.6755407653910149\n",
      "F1 128/200: 0.6738768718801996\n",
      "F1 129/200: 0.6788685524126455\n",
      "F1 130/200: 0.6788685524126455\n",
      "F1 131/200: 0.6788685524126455\n",
      "F1 132/200: 0.6772046589018302\n",
      "F1 133/200: 0.6772046589018302\n",
      "F1 134/200: 0.6821963394342762\n",
      "F1 135/200: 0.6838602329450915\n",
      "F1 136/200: 0.6838602329450915\n",
      "F1 137/200: 0.6838602329450915\n",
      "F1 138/200: 0.6838602329450915\n",
      "F1 139/200: 0.6838602329450915\n",
      "F1 140/200: 0.6871880199667221\n",
      "F1 141/200: 0.6871880199667221\n",
      "F1 142/200: 0.6871880199667221\n",
      "F1 143/200: 0.6871880199667221\n",
      "F1 144/200: 0.6871880199667221\n",
      "F1 145/200: 0.6871880199667221\n",
      "F1 146/200: 0.6871880199667221\n",
      "F1 147/200: 0.6871880199667221\n",
      "F1 148/200: 0.6871880199667221\n",
      "F1 149/200: 0.6871880199667221\n",
      "F1 150/200: 0.6888519134775375\n",
      "F1 151/200: 0.6905158069883528\n",
      "F1 152/200: 0.6905158069883528\n",
      "F1 153/200: 0.6905158069883528\n",
      "F1 154/200: 0.6905158069883528\n",
      "F1 155/200: 0.6905158069883528\n",
      "F1 156/200: 0.6888519134775375\n",
      "F1 157/200: 0.6888519134775375\n",
      "F1 158/200: 0.6888519134775375\n",
      "F1 159/200: 0.6888519134775375\n",
      "F1 160/200: 0.6888519134775375\n",
      "F1 161/200: 0.6888519134775375\n",
      "F1 162/200: 0.6888519134775375\n",
      "F1 163/200: 0.6888519134775375\n",
      "F1 164/200: 0.6888519134775375\n",
      "F1 165/200: 0.6871880199667221\n",
      "F1 166/200: 0.6871880199667221\n",
      "F1 167/200: 0.6871880199667221\n",
      "F1 168/200: 0.6871880199667221\n",
      "F1 169/200: 0.6871880199667221\n",
      "F1 170/200: 0.6871880199667221\n",
      "F1 171/200: 0.6871880199667221\n",
      "F1 172/200: 0.6855241264559068\n",
      "F1 173/200: 0.6855241264559068\n",
      "F1 174/200: 0.6838602329450915\n",
      "F1 175/200: 0.6838602329450915\n",
      "F1 176/200: 0.6838602329450915\n",
      "F1 177/200: 0.6821963394342762\n",
      "F1 178/200: 0.6821963394342762\n",
      "F1 179/200: 0.6821963394342762\n",
      "F1 180/200: 0.6805324459234608\n",
      "F1 181/200: 0.6805324459234608\n",
      "F1 182/200: 0.6805324459234608\n",
      "F1 183/200: 0.6805324459234608\n",
      "F1 184/200: 0.6788685524126455\n",
      "F1 185/200: 0.6788685524126455\n",
      "F1 186/200: 0.6772046589018302\n",
      "F1 187/200: 0.6772046589018302\n",
      "F1 188/200: 0.6772046589018302\n",
      "F1 189/200: 0.6772046589018302\n",
      "F1 190/200: 0.6772046589018302\n",
      "F1 191/200: 0.6788685524126455\n",
      "F1 192/200: 0.6788685524126455\n",
      "F1 193/200: 0.6788685524126455\n",
      "F1 194/200: 0.6788685524126455\n",
      "F1 195/200: 0.6755407653910149\n",
      "F1 196/200: 0.6755407653910149\n",
      "F1 197/200: 0.6772046589018302\n",
      "F1 198/200: 0.6772046589018302\n",
      "F1 199/200: 0.6772046589018302\n"
     ]
    }
   ],
   "source": [
    "model, losses, f1_valid = train(train_X, train_Y_nhot, valid_X, valid_Y_nhot, epochs=200, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x/(len(losses)/100) for x in range(len(losses))],losses, label=\"loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_valid, label='f1')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "bestIndex = np.argmax(f1_valid)\n",
    "bestNC, bestScore = np.arange(0, 200, 1)[bestIndex], f1_valid[bestIndex]\n",
    "plt.plot(bestNC, f1_valid[bestIndex], marker='X', color='green')\n",
    "plt.title(\"Best score: ~{0:.1%} (obtained on {1})\".format(bestScore, device))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Score du modèle fourni initialement : ~68%_\n",
    "\n",
    "C'est super! Vous avez fini."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
