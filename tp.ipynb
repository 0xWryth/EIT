{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOT3u0GZKWc8"
   },
   "source": [
    "# Réseau de neurones: les bases en numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Irgrskx6KWc-"
   },
   "source": [
    "Le but de ce TP est de voir les bases des réseaux de neurones en numpy. Puis de voir comment en pratique on s'en sert avec la librairie Pytorch.\n",
    "\n",
    "Ce TP sera **à rendre** (voir Discord).\n",
    "Il y a n points dans ce TP, qui seront divisé pour obtenir une note sur 4.\n",
    "\n",
    "Ce TP est à faire avec votre **groupe**. Rendez-le avec votre **groupe**.\n",
    "\n",
    "Si vous avez des **questions**, n'hésitez pas à me les poser sur **Discord**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlmi-culKWdA"
   },
   "source": [
    "## Lecture des données, tokenization et BoW\n",
    "\n",
    "Dans cette section vous devez lire les données (seulement les consensus).\n",
    "\n",
    "Vous devez construire votre tokenizer (et de préférence le sauvegarder).\n",
    "\n",
    "Vous devez transformer votre jeu de données (liste de tweets et labels) en liste de vecteurs BoW + liste d'indice des labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9Ekg9fkKWdD"
   },
   "outputs": [],
   "source": [
    "# Les imports sont préparé ici\n",
    "# n'enlevez pas les % car il permettent le reload de modules ou l'affichage dans le notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field, TabularDataset, Dataset, BucketIterator\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-b64e6fa215f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#train_dataset, test_dataset = Dataset.splits(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "TEXT = Field(sequential = True, lower=True, include_lengths = False,\n",
    "                  pad_token = \"<pad>\", unk_token = \"<unk>\",\n",
    "                  batch_first = True, tokenize = tokenizer)\n",
    "\n",
    "LABELS = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "\n",
    "trainset = Dataset([\"aled\", \"aled2\"], [('text', TEXT), ('labels', LABELS)])\n",
    "validset = Dataset([\"aled3\", \"aled4\"], [('text', TEXT), ('labels', LABELS)])\n",
    "\n",
    "trainset, validset\n",
    "\n",
    "type(trainset[0])\n",
    "\n",
    "#trainset.labels[1]\n",
    "\n",
    "#train_dataset, test_dataset = Dataset.splits(\n",
    "#    path='./',\n",
    "#    fields=[('text', TEXT), ('labels', LABELS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-4a211a206289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'glove.6B.50d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Size vocab :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0msources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=2, vectors = 'glove.6B.50d')\n",
    "print(\"Size vocab :\", len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-4a0e88a0b024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     shuffle = True, repeat=False)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, dataset, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\antonin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchtext\\legacy\\data\\batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    (trainset,  validset), batch_sizes=(16, 256),\n",
    "    sort_key = lambda x: len(x.text), device='cpu', \n",
    "    sort_within_batch = True, shuffle = True, repeat=False)\n",
    "\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 1** 1pt.\n",
    "\n",
    "Importez/réécrivez le code permettant de lire vos données et les transformer en BoW.\n",
    "\n",
    "A la fin de cette cellule, vous devrez avoir trois variables d'instanciées :\n",
    "- X : la liste des vecteurs BoW de vos tweets\n",
    "- Y_one_hot : la liste des indices des labels de vos tweets (Y_one_hot[i] doit contenir le label de X[i])\n",
    "- Y_one_hot : la liste des labels sous forme one_hot (c'est similaire à un BoW, vous prenez un vecteur de zeros et mettez un 1 à l'indice du label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G74xriNqIWKU"
   },
   "outputs": [],
   "source": [
    "def read_corpus(path, consensus=False):\n",
    "    f = open(path, 'r', encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    corpus = []\n",
    "    for l in lines:\n",
    "        sl = l.split()\n",
    "        if len(sl) == 0:\n",
    "            continue\n",
    "        if consensus:\n",
    "            m = re.match(r\"[(](.*),(.*),(consensus)[)]\", sl[0])\n",
    "            if m is not None:\n",
    "                corpus.append([sl[1:], sl[0]])\n",
    "        else:\n",
    "            corpus.append([sl[1:], sl[0]])\n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "class WordTokenizer:\n",
    "    def __init__(self, bos='BOS', eos='EOS', unk='UNK', pad='PAD'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.word2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2word = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sent):\n",
    "        \"\"\"\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                self.word2id[w] = len(self.id2word.keys())\n",
    "                self.id2word[self.word2id[w]] = w\n",
    "\n",
    "    def str_to_ids(self, sentence):\n",
    "        sent = sentence.split()\n",
    "        ret = []\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                ret.append(self.word2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.word2id[w])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def words_to_ids(self, sent):\n",
    "        ret = []\n",
    "        for w in sent:\n",
    "            if w not in self.word2id.keys():\n",
    "                ret.append(self.word2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.word2id[w])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_words(self, ids):\n",
    "        words = []\n",
    "        for i in ids:\n",
    "            words.append(self.id2word[i])\n",
    "        return words\n",
    "\n",
    "\n",
    "class CharTokenizer:\n",
    "    def __init__(self, bos='<B>', eos='<E>', unk='<U>', pad='<P>'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.char2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2char = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sentence):\n",
    "        \"\"\"\n",
    "        adds vocabulary (chars) found in sentence to the dictionaries\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for w in sentence:\n",
    "            if w not in self.char2id.keys():\n",
    "                self.char2id[w] = len(self.id2char.keys())\n",
    "                self.id2char[self.char2id[w]] = w\n",
    "\n",
    "    def chars_to_ids(self, sentence):\n",
    "        ret = []\n",
    "        for c in sentence:\n",
    "            if c not in self.char2id.keys():\n",
    "                ret.append(self.char2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.char2id[c])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_chars(self, ids):\n",
    "        chars = \"\"\n",
    "        for i in ids:\n",
    "            chars += self.id2char[i]\n",
    "        return chars\n",
    "\n",
    "\n",
    "class TrigramTokenizer:\n",
    "    def __init__(self, bos='<B>', eos='<E>', unk='<U>', pad='<P>'):\n",
    "\n",
    "        self.pad = pad\n",
    "        self.unk = unk\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "\n",
    "        self.char2id = {pad: 0,\n",
    "                        unk: 1,\n",
    "                        bos: 2,\n",
    "                        eos: 3}\n",
    "\n",
    "        self.id2char = {0: pad,\n",
    "                        1: unk,\n",
    "                        2: bos,\n",
    "                        3: eos}\n",
    "\n",
    "    def add_to_voc(self, sentence):\n",
    "        \"\"\"\n",
    "        adds vocabulary (chars) found in sentence to the dictionaries\n",
    "        :param sentence: string\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for i in range(len(sentence)-3):\n",
    "            if sentence[i:i+3] not in self.char2id.keys():\n",
    "                self.char2id[sentence[i:i+3]] = len(self.id2char.keys())\n",
    "                self.id2char[self.char2id[sentence[i:i+3]]] = sentence[i:i+3]\n",
    "\n",
    "    def chars_to_ids(self, sentence):\n",
    "        ret = []\n",
    "        for i in range(len(sentence)-3):\n",
    "            if sentence[i:i+3] not in self.char2id.keys():\n",
    "                ret.append(self.char2id[self.unk])\n",
    "            else:\n",
    "                ret.append(self.char2id[sentence[i:i+3]])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def ids_to_chars(self, ids):\n",
    "        chars = \"\"\n",
    "        for i in ids:\n",
    "            chars += self.id2char[i]\n",
    "        return chars\n",
    "\n",
    "def list_to_bow(sent, dic):\n",
    "    \"sent list of ids, dic: dictionary {word, index}\"\n",
    "    vec = np.zeros(len(dic), dtype=int)\n",
    "    for i in sent:\n",
    "        vec[i] = 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "def list_to_bow_freq(sent, dic):\n",
    "    vec = np.zeros(len(dic))\n",
    "    for i in sent:\n",
    "        vec[i] += 1\n",
    "    for i in range(len(vec)):\n",
    "        vec[i] = vec[i] / len(sent)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def n_grams(sents, n):\n",
    "\n",
    "    new_sents = []\n",
    "    dic = {}\n",
    "\n",
    "    for s in sents:\n",
    "        ns = []\n",
    "        for i in range(len(s)-(n-1)):\n",
    "            t = \"\"\n",
    "            for j in range(n):\n",
    "                t += f\"{s[i+j]} \"\n",
    "            t = t[:-1]\n",
    "            ns.append(t)\n",
    "            if t not in dic:\n",
    "                dic[t] = len(dic.keys())\n",
    "\n",
    "        new_sents.append(ns)\n",
    "    return new_sents, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "11762\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "11762\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# mettez votre code ici\n",
    "\n",
    "corpus = read_corpus(\"./train_label_final.txt\", consensus=True)\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "labels = {'pos': 0, 'neg': 1, 'neu': 2, 'irr': 3}\n",
    "Y_one_hot = [] # Pour les labels il faut des vecteurs en one_hot, par exemple pour irr : [0,0,0,1]\n",
    "Y = []\n",
    "for i in range(len(corpus)):\n",
    "    lab = re.match(r\"[(].*,(.*),.*[)]\", corpus[i][1])\n",
    "    ap = np.zeros(len(labels.keys()))\n",
    "    ap[labels[lab[1].lower()]] = 1\n",
    "    Y.append(labels[lab[1].lower()])\n",
    "    Y_one_hot.append(ap)\n",
    "\n",
    "\n",
    "tweets = [c[0] for c in corpus]\n",
    "for t in tweets:\n",
    "    tokenizer.add_to_voc(t)\n",
    "\n",
    "    \n",
    "tweets_ids = [tokenizer.words_to_ids(t) for t in tweets]\n",
    "\n",
    "\n",
    "X = [list_to_bow(tw, tokenizer.word2id) for tw in tweets_ids]\n",
    "X_freq = [list_to_bow_freq(tw, tokenizer.word2id) for tw in tweets_ids]\n",
    "\n",
    "\n",
    "print(X[0]) # x sont les tweets transformés en vecteurs BoW\n",
    "print(len(X[0]))\n",
    "print(X_freq[0])\n",
    "print(len(X_freq[0]))\n",
    "print(Y_one_hot[0]) # y sont les labels transformés en indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvZIFXNNKWdV"
   },
   "source": [
    "## Création du modèle\n",
    "\n",
    "Nous allons d'abord créer une couche linéaire.\n",
    "Celle ci comprendra le terme de biais.\n",
    "\n",
    "Rappel de la formule de la couche linéaire: \n",
    "$$\n",
    "\\mathbf{a} = \\mathbf{W}\\mathbf{x}+ \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Notons *n_in* et *n_out* respectivement les dimensions de $\\mathbf{x}$ et $\\mathbf{y}$. \n",
    "\n",
    "**Tache 2** 1pt.\n",
    "- Coder la fonction d'initialisation suivante, l'initialisation est aléatoire Gaussien centrée en 0 avec un écart type 1 / sqrt(n_in). La fonction retourne W et b. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzcMLu1KKWdx"
   },
   "source": [
    "## Algorithme d'apprentissage \n",
    "\n",
    "On a tout ce qu'il faut pour mettre en oeuvre l'apprentissage d'un modèle simple. Le modèle est simplement une couche neuronale de sortie, sans couche cachée. \n",
    "\n",
    "L'algorithme se déroule en 2 temps, tout d'abord la préparation: \n",
    "- initialisation du modèle\n",
    "- préparation des données et des variables permettant de stocker l'historique d'apprentissage\n",
    "- initialisation des paramètres de l'algorithme d'optimisation Adam\n",
    "- définir le nombre d'époque comme une variable\n",
    "\n",
    "Puis vient la boucle d'apprentissage qui pour chaque époque effectue pour chaque exemple d'apprentissage : \n",
    "- inférence du modèle sur l'exemple d'apprentissage \n",
    "- calcul de la contribution de l'exemple à la  fonction objectif, et également au taux d'erreur de classification\n",
    "- Calcul du gradient de sortie\n",
    "- Mise à jour du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 :  PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de cette section est de répliquer ce que vous avez fait à la main grâce à une librairie spécialisée.\n",
    "\n",
    "Cette librairie est Pytorch.\n",
    "\n",
    "Dans cette librairie vous retrouverez la gestion des poids sous forme de couches dans le sous-module nn.\n",
    "La gestion du gradient est quasiment automatique.\n",
    "\n",
    "Le jeu de données sera toujours les vecteurs BoW obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:1500]\n",
    "train_Y = Y_one_hot[:1500]\n",
    "train_Y_nhot = Y[:1500]\n",
    "\n",
    "valid_X = X[1500:]\n",
    "valid_Y = Y_one_hot[1500:]\n",
    "valid_Y_nhot = Y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import f1_score\n",
    "import torchtext\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "device = 'cuda' if T.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 11** 3 pt\n",
    "\n",
    "Implémentez le même modèle que précédemment.\n",
    "\n",
    "Utilisez les couches Linear et LogSoftmax (les probabilités sont souvent des logs probabilités).\n",
    "Cherchez dans la documentation de torch.nn pour les couches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): # pour faire un modèle dans pytorch il faut instancier la classe nn.Module\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim) # Ici se trouve la couche Wx + b\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # Pour pytorch, la plupars des fonction fonctionne avec des logarithmes\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Quelque soit le modèle, il vous faut une fonction forward\n",
    "        # Pour calculer la sortie d'une couche : y = couche(x) avec x un tensor\n",
    "        #embeds = self.embeding(inputs.to(T.int64))\n",
    "        # print(inputs.shape)\n",
    "        y = T.tanh(self.linear1(inputs))\n",
    "        preds = self.softmax(y)\n",
    "        return preds    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tache 12** 2pt\n",
    "\n",
    "Complétez la boucle d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "    return T.stack(transposed_data[0], 0), T.stack(transposed_data[1], 0)\n",
    "\n",
    "def train(train_X, train_Y, valid_X, valid_Y, epochs=100, batch_size=64, lr = 1e-3):\n",
    "    model = Model(len(train_X[0]), 4).to(device)\n",
    "    \n",
    "    opti = T.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss() # Pour calculer la crossentropy, il faut calculer la NLLL après un logsofmax\n",
    "    \n",
    "    \n",
    "    ## Transformation des données pour l'entraînement\n",
    "    #trn_X = [T.tensor(x, dtype=T.long) for x in train_X]\n",
    "    #trn_Y = [T.tensor(y, dtype=T.long) for y in train_Y]\n",
    "    \n",
    "    #vld_X = [T.tensor(x, dtype=T.long) for x in valid_X]\n",
    "    #vld_Y = [T.tensor(y, dtype=T.long) for y in valid_Y]\n",
    "    \n",
    "    trn_X = T.tensor(train_X, dtype=T.float)\n",
    "    trn_Y = T.tensor(train_Y, dtype=T.long)\n",
    "    \n",
    "    vld_X = T.tensor(valid_X, dtype=T.float)\n",
    "    vld_Y = T.tensor(valid_Y, dtype=T.long)\n",
    "    \n",
    "    train_set = data.TensorDataset(trn_X, trn_Y)\n",
    "    valid_set = data.TensorDataset(vld_X, vld_Y)\n",
    "    \n",
    "    \n",
    "    ## Creation des loaders\n",
    "    train_sampler = data.BatchSampler(data.RandomSampler(range(len(train_X))), batch_size, False)\n",
    "    valid_sampler = data.BatchSampler(data.SequentialSampler(range(len(valid_X))), len(valid_X), False)\n",
    "    \n",
    "    train_loader = data.DataLoader(train_set, batch_sampler=train_sampler, collate_fn=collate)\n",
    "    valid_loader = data.DataLoader(valid_set, batch_sampler=valid_sampler, collate_fn=collate)\n",
    "    \n",
    "    \n",
    "    losses = []\n",
    "    f1_valid = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        model.train() #passe votre modele en phase d'entrainement \n",
    "        \n",
    "        for batch_ndx, (trn_x, trn_y) in enumerate(train_loader):\n",
    "            opti.zero_grad()\n",
    "            \n",
    "            preds = model(trn_x.to(device))\n",
    "            loss = criterion(preds, trn_y.to(device))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            \n",
    "        opti.zero_grad()\n",
    "        model.eval()\n",
    "        \n",
    "        with T.no_grad(): # pour gagner du temps en ne générant pas de graphe pour la validation\n",
    "            for batch_ndx, (vld_x, vld_y) in enumerate(valid_loader):\n",
    "\n",
    "                preds_val = model(vld_x.to(device))\n",
    "                preds = T.argmax(preds_val, dim=1)\n",
    "                f1_valid.append(f1_score(vld_y.to('cpu').numpy(), preds.to('cpu').numpy(), average='micro',\n",
    "                                labels=[i for i in range(4)]))\n",
    "        print(f\"F1 {e}/{epochs}: {f1_valid[-1]}\")\n",
    "    \n",
    "    return model, losses, f1_valid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-b435f4754082>:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  trn_X = T.tensor(train_X, dtype=T.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0/200: 0.39434276206322794\n",
      "F1 1/200: 0.502495840266223\n",
      "F1 2/200: 0.5806988352745425\n",
      "F1 3/200: 0.5990016638935108\n",
      "F1 4/200: 0.6023294509151415\n",
      "F1 5/200: 0.6023294509151415\n",
      "F1 6/200: 0.6073211314475874\n",
      "F1 7/200: 0.6123128119800333\n",
      "F1 8/200: 0.6173044925124792\n",
      "F1 9/200: 0.6139767054908486\n",
      "F1 10/200: 0.6139767054908486\n",
      "F1 11/200: 0.610648918469218\n",
      "F1 12/200: 0.6222961730449251\n",
      "F1 13/200: 0.6222961730449251\n",
      "F1 14/200: 0.6222961730449251\n",
      "F1 15/200: 0.6222961730449251\n",
      "F1 16/200: 0.6206322795341098\n",
      "F1 17/200: 0.6206322795341098\n",
      "F1 18/200: 0.6222961730449251\n",
      "F1 19/200: 0.6206322795341098\n",
      "F1 20/200: 0.6189683860232945\n",
      "F1 21/200: 0.6206322795341098\n",
      "F1 22/200: 0.6206322795341098\n",
      "F1 23/200: 0.6206322795341098\n",
      "F1 24/200: 0.6206322795341098\n",
      "F1 25/200: 0.6189683860232945\n",
      "F1 26/200: 0.6206322795341098\n",
      "F1 27/200: 0.6206322795341098\n",
      "F1 28/200: 0.6206322795341098\n",
      "F1 29/200: 0.6206322795341098\n",
      "F1 30/200: 0.6206322795341098\n",
      "F1 31/200: 0.6189683860232945\n",
      "F1 32/200: 0.6189683860232945\n",
      "F1 33/200: 0.6189683860232945\n",
      "F1 34/200: 0.6206322795341098\n",
      "F1 35/200: 0.6222961730449251\n",
      "F1 36/200: 0.6222961730449251\n",
      "F1 37/200: 0.6222961730449251\n",
      "F1 38/200: 0.6222961730449251\n",
      "F1 39/200: 0.6222961730449251\n",
      "F1 40/200: 0.6222961730449251\n",
      "F1 41/200: 0.6256239600665557\n",
      "F1 42/200: 0.6306156405990017\n",
      "F1 43/200: 0.632279534109817\n",
      "F1 44/200: 0.632279534109817\n",
      "F1 45/200: 0.6339434276206323\n",
      "F1 46/200: 0.6339434276206323\n",
      "F1 47/200: 0.632279534109817\n",
      "F1 48/200: 0.6339434276206323\n",
      "F1 49/200: 0.6339434276206323\n",
      "F1 50/200: 0.6372712146422629\n",
      "F1 51/200: 0.6372712146422629\n",
      "F1 52/200: 0.6372712146422629\n",
      "F1 53/200: 0.6372712146422629\n",
      "F1 54/200: 0.6405990016638935\n",
      "F1 55/200: 0.6405990016638935\n",
      "F1 56/200: 0.6405990016638935\n",
      "F1 57/200: 0.6405990016638935\n",
      "F1 58/200: 0.6405990016638935\n",
      "F1 59/200: 0.6405990016638935\n",
      "F1 60/200: 0.6439267886855241\n",
      "F1 61/200: 0.6472545757071547\n",
      "F1 62/200: 0.64891846921797\n",
      "F1 63/200: 0.6505823627287853\n",
      "F1 64/200: 0.6505823627287853\n",
      "F1 65/200: 0.6505823627287853\n",
      "F1 66/200: 0.6505823627287853\n",
      "F1 67/200: 0.6522462562396006\n",
      "F1 68/200: 0.6505823627287853\n",
      "F1 69/200: 0.6522462562396006\n",
      "F1 70/200: 0.6522462562396006\n",
      "F1 71/200: 0.6522462562396006\n",
      "F1 72/200: 0.6522462562396006\n",
      "F1 73/200: 0.6522462562396006\n",
      "F1 74/200: 0.653910149750416\n",
      "F1 75/200: 0.653910149750416\n",
      "F1 76/200: 0.653910149750416\n",
      "F1 77/200: 0.6522462562396006\n",
      "F1 78/200: 0.653910149750416\n",
      "F1 79/200: 0.653910149750416\n",
      "F1 80/200: 0.653910149750416\n",
      "F1 81/200: 0.653910149750416\n",
      "F1 82/200: 0.653910149750416\n",
      "F1 83/200: 0.653910149750416\n",
      "F1 84/200: 0.653910149750416\n",
      "F1 85/200: 0.653910149750416\n",
      "F1 86/200: 0.6522462562396006\n",
      "F1 87/200: 0.653910149750416\n",
      "F1 88/200: 0.6555740432612313\n",
      "F1 89/200: 0.6555740432612313\n",
      "F1 90/200: 0.6572379367720466\n",
      "F1 91/200: 0.6572379367720466\n",
      "F1 92/200: 0.6572379367720466\n",
      "F1 93/200: 0.6589018302828619\n",
      "F1 94/200: 0.6605657237936772\n",
      "F1 95/200: 0.6622296173044925\n",
      "F1 96/200: 0.6622296173044925\n",
      "F1 97/200: 0.6622296173044925\n",
      "F1 98/200: 0.6622296173044925\n",
      "F1 99/200: 0.6622296173044925\n",
      "F1 100/200: 0.6622296173044925\n",
      "F1 101/200: 0.6655574043261231\n",
      "F1 102/200: 0.6672212978369384\n",
      "F1 103/200: 0.6672212978369384\n",
      "F1 104/200: 0.6655574043261231\n",
      "F1 105/200: 0.6655574043261231\n",
      "F1 106/200: 0.6655574043261231\n",
      "F1 107/200: 0.6655574043261231\n",
      "F1 108/200: 0.6655574043261231\n",
      "F1 109/200: 0.6655574043261231\n",
      "F1 110/200: 0.6655574043261231\n",
      "F1 111/200: 0.6655574043261231\n",
      "F1 112/200: 0.6655574043261231\n",
      "F1 113/200: 0.6672212978369384\n",
      "F1 114/200: 0.6688851913477537\n",
      "F1 115/200: 0.6688851913477537\n",
      "F1 116/200: 0.6688851913477537\n",
      "F1 117/200: 0.6688851913477537\n",
      "F1 118/200: 0.6688851913477537\n",
      "F1 119/200: 0.670549084858569\n",
      "F1 120/200: 0.670549084858569\n",
      "F1 121/200: 0.670549084858569\n",
      "F1 122/200: 0.6722129783693843\n",
      "F1 123/200: 0.6738768718801996\n",
      "F1 124/200: 0.6738768718801996\n",
      "F1 125/200: 0.6755407653910149\n",
      "F1 126/200: 0.6755407653910149\n",
      "F1 127/200: 0.6755407653910149\n",
      "F1 128/200: 0.6772046589018302\n",
      "F1 129/200: 0.6788685524126455\n",
      "F1 130/200: 0.6788685524126455\n",
      "F1 131/200: 0.6805324459234608\n",
      "F1 132/200: 0.6821963394342762\n",
      "F1 133/200: 0.6838602329450915\n",
      "F1 134/200: 0.6838602329450915\n",
      "F1 135/200: 0.6838602329450915\n",
      "F1 136/200: 0.6838602329450915\n",
      "F1 137/200: 0.6838602329450915\n",
      "F1 138/200: 0.6838602329450915\n",
      "F1 139/200: 0.6871880199667221\n",
      "F1 140/200: 0.6905158069883528\n",
      "F1 141/200: 0.6888519134775375\n",
      "F1 142/200: 0.6888519134775375\n",
      "F1 143/200: 0.6888519134775375\n",
      "F1 144/200: 0.6888519134775375\n",
      "F1 145/200: 0.6888519134775375\n",
      "F1 146/200: 0.6905158069883528\n",
      "F1 147/200: 0.6888519134775375\n",
      "F1 148/200: 0.6888519134775375\n",
      "F1 149/200: 0.6888519134775375\n",
      "F1 150/200: 0.6905158069883528\n",
      "F1 151/200: 0.6905158069883528\n",
      "F1 152/200: 0.6905158069883528\n",
      "F1 153/200: 0.6905158069883528\n",
      "F1 154/200: 0.6871880199667221\n",
      "F1 155/200: 0.6871880199667221\n",
      "F1 156/200: 0.6871880199667221\n",
      "F1 157/200: 0.6871880199667221\n",
      "F1 158/200: 0.6871880199667221\n",
      "F1 159/200: 0.6871880199667221\n",
      "F1 160/200: 0.6871880199667221\n",
      "F1 161/200: 0.6871880199667221\n",
      "F1 162/200: 0.6871880199667221\n",
      "F1 163/200: 0.6871880199667221\n",
      "F1 164/200: 0.6871880199667221\n",
      "F1 165/200: 0.6838602329450915\n",
      "F1 166/200: 0.6838602329450915\n",
      "F1 167/200: 0.6838602329450915\n",
      "F1 168/200: 0.6838602329450915\n",
      "F1 169/200: 0.6838602329450915\n",
      "F1 170/200: 0.6821963394342762\n",
      "F1 171/200: 0.6855241264559068\n",
      "F1 172/200: 0.6821963394342762\n",
      "F1 173/200: 0.6838602329450915\n",
      "F1 174/200: 0.6838602329450915\n",
      "F1 175/200: 0.6821963394342762\n",
      "F1 176/200: 0.6838602329450915\n",
      "F1 177/200: 0.6855241264559068\n",
      "F1 178/200: 0.6871880199667221\n",
      "F1 179/200: 0.6871880199667221\n",
      "F1 180/200: 0.6888519134775375\n",
      "F1 181/200: 0.6855241264559068\n",
      "F1 182/200: 0.6855241264559068\n",
      "F1 183/200: 0.6871880199667221\n",
      "F1 184/200: 0.6871880199667221\n",
      "F1 185/200: 0.6871880199667221\n",
      "F1 186/200: 0.6871880199667221\n",
      "F1 187/200: 0.6871880199667221\n",
      "F1 188/200: 0.6855241264559068\n",
      "F1 189/200: 0.6855241264559068\n",
      "F1 190/200: 0.6838602329450915\n",
      "F1 191/200: 0.6855241264559068\n",
      "F1 192/200: 0.6821963394342762\n",
      "F1 193/200: 0.6821963394342762\n",
      "F1 194/200: 0.6805324459234608\n",
      "F1 195/200: 0.6805324459234608\n",
      "F1 196/200: 0.6805324459234608\n",
      "F1 197/200: 0.6805324459234608\n",
      "F1 198/200: 0.6805324459234608\n",
      "F1 199/200: 0.6805324459234608\n"
     ]
    }
   ],
   "source": [
    "model, losses, f1_valid = train(train_X, train_Y_nhot, valid_X, valid_Y_nhot, epochs=200, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([x/(len(losses)/100) for x in range(len(losses))],losses, label=\"loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_valid, label='f1')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "bestIndex = np.argmax(f1_valid)\n",
    "bestNC, bestScore = np.arange(0, 200, 1)[bestIndex], f1_valid[bestIndex]\n",
    "plt.plot(bestNC, f1_valid[bestIndex], marker='X', color='green')\n",
    "plt.title(\"Best score: ~{0:.1%} (obtained on {1})\".format(bestScore, device))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Score du modèle fourni initialement : ~68%_\n",
    "\n",
    "C'est super! Vous avez fini."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
